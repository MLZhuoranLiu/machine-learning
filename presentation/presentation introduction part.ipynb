{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Boltzmann Machine\n",
    "\n",
    "Boltzmann machine is a general learning rule applicable to any stochastic network with symmetric connections. <br />\n",
    "It was firstly introduced by Hinton and Sejnowski in 1983. The name Boltamann machine is because the probability of the states of the system is given by the Boltzmann-Gibbs distribution of statistical mechanics. <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rule\n",
    "The central rule for Boltzmann machine are:<br />\n",
    "$$\\frac{\\partial L}{\\partial \\theta_i} = \\langle S_i \\rangle_c - \\langle S_i \\rangle$$\n",
    "$$\\frac{\\partial L}{\\partial w_{ij}} = \\langle S_iS_j \\rangle_c - \\langle S_iS_j \\rangle$$\n",
    "\n",
    "Here the two formulas are the gradients of the log likelihood of observed data with respect to biases and weights. The clamped data is an expected value in the data distribution. The un-clamped data is an expected value when the Boltzmann machine is sampling state vectors from its equilibrium distribution at a particular temperature.<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main learning process\n",
    "The learning process will adjust the weights and biases in each iteration using these two formulas until convergence. <br />\n",
    "Every time we need to calculate $\\langle S_iS_j \\rangle$ and  $\\langle S_i \\rangle$ in both clamped and un-clamped state for each pattern. <br />\n",
    "To calculate them, we must come the equilibrium and sample many units from its equilibrium distribution at a temperature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deterministic Boltzmann machine\n",
    "In the original form, the Boltzmann learning algorithm is very slow because of the need for extensive stochastic variables, in particular the un-clamped$\\langle S_iS_j \\rangle$.  <br />\n",
    "There are few applications compared with back-propagation, and the mean filed theory version is mainly considered. <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Boltzmann Machine\n",
    "\n",
    "Boltzmann machine is a general learning rule applicable to any stochastic network with symmetric connections. <br />\n",
    "It was firstly introduced by Hinton and Sejnowski in 1983. The name Boltamann machine is because the probability of the states of the system is given by the Boltzmann-Gibbs distribution of statistical mechanics. <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rule\n",
    "The central rule for Boltzmann machine are:<br />\n",
    "$$\\frac{\\partial L}{\\partial \\theta_i} = \\langle S_i \\rangle_c - \\langle S_i \\rangle$$\n",
    "$$\\frac{\\partial L}{\\partial w_{ij}} = \\langle S_iS_j \\rangle_c - \\langle S_iS_j \\rangle$$\n",
    "\n",
    "Here the two formulas are the gradients of the log likelihood of observed data with respect to biases and weights. The clamped data is an expected value in the data distribution. The un-clamped data is an expected value when the Boltzmann machine is sampling state vectors from its equilibrium distribution at a particular temperature.<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main learning process\n",
    "The learning process will adjust the weights and biases in each iteration using these two formulas until convergence. <br />\n",
    "Every time we need to calculate $\\langle S_iS_j \\rangle$ and  $\\langle S_i \\rangle$ in both clamped and un-clamped state for each pattern. <br />\n",
    "To calculate them, we must come the equilibrium and sample many units from its equilibrium distribution at a temperature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deterministic Boltzmann machine\n",
    "In the original form, the Boltzmann learning algorithm is very slow because of the need for extensive stochastic variables, in particular the un-clamped$\\langle S_iS_j \\rangle$.  <br />\n",
    "There are few applications compared with back-propagation, and the mean filed theory version is mainly considered. <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Normalizing Constant\n",
    "\n",
    "In the learning procedure, probabilities of state vectors are needed in order to compute the gradients. For these probabilities, a normalizing constant is needed. This requires to sum over all possible $2^n$ states where $n$ is the number of units - which takes a very long time.\n",
    "\n",
    "In the first part of the assignment, we approximated the normalizing constant as follows. Since all the probabilities should sum up to $1$, we know that:\n",
    "\n",
    "$\\begin{align}\n",
    "1 = \\frac{1}{Z} \\sum\\limits_{\\textbf{s}} \\exp(-E(\\textbf{s} ))\n",
    "\\end{align}$\n",
    "\n",
    "So therefore, $Z = \\sum\\limits_{\\textbf{s}} \\exp(-E(\\textbf{s} ))$. The states that contribute the most to $Z$ are the states with low energies.\n",
    "\n",
    "### Sequential Dynamics\n",
    "\n",
    "With sequential dynamics, a random state is initialized. Then, one of the neurons is picked and is changed according to the Boltzmann-Gibbs distribution. This is repeated many times. The energy of the system will be minimized and therefore states can be sampled which have low energy. Now we can approximate $Z$ be summing over these sampled states. Other states will contribute less to $Z$ and will be neglected.\n",
    "\n",
    "### Mean Field Approximation\n",
    "\n",
    "Using Mean Field Approximation, $Z$ is approximated by calculated the free energy in the system and then calculate $Z$ directly from it using $Z = \\exp(-F)$. This is way faster, because we do not need to take samples from the Boltzmann-Gibbs distribution in order to train the Boltzmann Machine.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Use the Mean Field Approximation whenever this is possible to avoid the computational burden on computing the normalizing constant. Otherwise, take samples from the Boltzmann-Gibbs distribution and approximate the normalizing constant and if the number of units is extremely small, $Z$ can be computed by bruteforcing all possible states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
